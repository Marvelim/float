#!/usr/bin/env python3
"""
å¿«é€Ÿæ•°æ®é›†æµ‹è¯•è„šæœ¬
ç®€åŒ–ç‰ˆæœ¬ï¼Œç”¨äºå¿«é€ŸéªŒè¯æ•°æ®é›†åŠ è½½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import torch
import traceback
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from training.dataset import FLOATDataset
from options.base_options import BaseOptions


def quick_test():
    """å¿«é€Ÿæµ‹è¯•æ•°æ®é›†åŠ è½½"""
    print("ğŸš€ å¿«é€Ÿæ•°æ®é›†æµ‹è¯•å¼€å§‹...")
    
    try:
        # è§£æé…ç½®
        opt = BaseOptions().parse()
        print(f"ğŸ“ æ•°æ®æ ¹ç›®å½•: {opt.data_root}")
        
        # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(opt.data_root):
            print(f"âŒ æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {opt.data_root}")
            print("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨ï¼Œæˆ–ä½¿ç”¨ --data_root å‚æ•°æŒ‡å®šæ­£ç¡®çš„è·¯å¾„")
            return False
        
        # åˆ›å»ºæ•°æ®é›†
        print("ğŸ”„ åˆ›å»ºæ•°æ®é›†...")
        dataset = FLOATDataset(
            data_root=opt.data_root,
            train=True,
            opt=opt
        )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼")
        print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        if len(dataset) == 0:
            print("âš ï¸  è­¦å‘Š: æ•°æ®é›†ä¸ºç©º")
            print("ğŸ’¡ è¯·æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„å’Œæ–‡ä»¶æ˜¯å¦æ­£ç¡®")
            return False
        
        # æµ‹è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ•°æ®é¡¹
        print("ğŸ”„ æµ‹è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ•°æ®é¡¹...")
        data_item = dataset[0]
        
        print("âœ… æ•°æ®é¡¹åŠ è½½æˆåŠŸï¼")
        print("ğŸ“‹ æ•°æ®é¡¹åŒ…å«çš„é”®:")
        for key, value in data_item.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {tuple(value.shape)} ({value.dtype})")
            else:
                print(f"   {key}: {type(value)} = {value}")
        
        # ç®€å•çš„æ•°æ®éªŒè¯
        required_keys = ['video_cur', 'audio_latent_cur', 'emotion_features']
        missing_keys = [key for key in required_keys if key not in data_item]
        
        if missing_keys:
            print(f"âš ï¸  ç¼ºå°‘å¿…è¦çš„é”®: {missing_keys}")
        else:
            print("âœ… åŒ…å«æ‰€æœ‰å¿…è¦çš„æ•°æ®é”®")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        tensor_keys = ['video_cur', 'motion_latent_cur', 'audio_latent_cur']
        for key in tensor_keys:
            if key in data_item and not isinstance(data_item[key], torch.Tensor):
                print(f"âš ï¸  {key} ä¸æ˜¯ torch.Tensor ç±»å‹")
        
        print("\nğŸ‰ å¿«é€Ÿæµ‹è¯•å®Œæˆï¼æ•°æ®é›†åŸºæœ¬åŠŸèƒ½æ­£å¸¸ã€‚")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        print("ğŸ” é”™è¯¯è¯¦æƒ…:")
        print(traceback.format_exc())
        return False


def test_with_custom_config():
    """ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æµ‹è¯•"""
    print("ğŸ”§ ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æµ‹è¯•...")
    
    # åˆ›å»ºä¸€ä¸ªæœ€å°é…ç½®
    class MinimalConfig:
        def __init__(self):
            # å¿…è¦çš„é…ç½®é¡¹
            self.input_size = 512
            self.dim_w = 512
            self.dim_m = 20
            self.dim_a = 512
            self.dim_e = 7
            self.wav2vec_sec = 0.64
            self.fps = 25
            self.num_prev_frames = 4
            self.sampling_rate = 16000
            self.wav2vec_model_path = "./checkpoints/wav2vec2-base-960h"
            self.audio2emotion_path = "./checkpoints/wav2vec-english-speech-emotion-recognition"
            self.only_last_features = True
            
            # æ•°æ®è·¯å¾„
            self.data_root = "/home/mli374/float/datasets"  # é»˜è®¤è·¯å¾„
    
    try:
        opt = MinimalConfig()
        
        # æ£€æŸ¥å¿…è¦çš„æ¨¡å‹æ–‡ä»¶
        model_files = [opt.wav2vec_model_path, opt.audio2emotion_path]
        missing_models = [f for f in model_files if not os.path.exists(f)]
        
        if missing_models:
            print("âš ï¸  ç¼ºå°‘æ¨¡å‹æ–‡ä»¶:")
            for f in missing_models:
                print(f"   {f}")
            print("ğŸ’¡ è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼Œæˆ–ä¸‹è½½ç›¸åº”çš„é¢„è®­ç»ƒæ¨¡å‹")
        
        # å°è¯•åˆ›å»ºæ•°æ®é›†
        dataset = FLOATDataset(
            data_root=opt.data_root,
            train=True,
            opt=opt
        )
        
        print(f"âœ… ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»ºæ•°æ®é›†æˆåŠŸï¼å¤§å°: {len(dataset)}")
        return True
        
    except Exception as e:
        print(f"âŒ è‡ªå®šä¹‰é…ç½®æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def check_data_structure():
    """æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„"""
    print("ğŸ” æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„...")
    
    # å¸¸è§çš„æ•°æ®ç›®å½•ç»“æ„
    possible_paths = [
        "/home/mli374/float/datasets",
        "./datasets",
        "../datasets",
        "./datasets/ravdess_processed",
        "./datasets/ravdess_raw"
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            print(f"âœ… æ‰¾åˆ°ç›®å½•: {path}")
            
            # åˆ—å‡ºå­ç›®å½•
            try:
                subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]
                if subdirs:
                    print(f"   å­ç›®å½•: {subdirs[:5]}{'...' if len(subdirs) > 5 else ''}")
                else:
                    print("   (æ— å­ç›®å½•)")
            except PermissionError:
                print("   (æ— æ³•è®¿é—®)")
        else:
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {path}")
    
    return True


def main():
    parser = argparse.ArgumentParser(description='å¿«é€Ÿæ•°æ®é›†æµ‹è¯•')
    parser.add_argument('--data_root', type=str,
                       help='æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--check_structure', action='store_true',
                       help='æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„')
    parser.add_argument('--custom_config', action='store_true',
                       help='ä½¿ç”¨è‡ªå®šä¹‰æœ€å°é…ç½®æµ‹è¯•')

    args = parser.parse_args()

    success = True

    # æ£€æŸ¥æ•°æ®ç»“æ„
    if args.check_structure:
        check_data_structure()
        return

    # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æµ‹è¯•
    if args.custom_config:
        success &= test_with_custom_config()

    # å¦‚æœæŒ‡å®šäº†data_rootï¼Œä¸´æ—¶ä¿®æ”¹ç¯å¢ƒ
    if args.data_root:
        # ä¿®æ”¹å‘½ä»¤è¡Œå‚æ•°ï¼Œè®©BaseOptionsèƒ½å¤Ÿè§£æåˆ°
        sys.argv.extend(['--data_root', args.data_root])

    # è¿è¡Œå¿«é€Ÿæµ‹è¯•
    success &= quick_test()

    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ’¡ å¦‚éœ€æ›´è¯¦ç»†çš„æµ‹è¯•ï¼Œè¯·è¿è¡Œ: python test_dataset.py")
        print("ğŸ’¡ æ‰€æœ‰é…ç½®éƒ½é€šè¿‡ BaseOptions ç®¡ç†ï¼Œæ— éœ€ JSON é…ç½®æ–‡ä»¶")
    else:
        print("\nğŸ’¥ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®æ–‡ä»¶")
        print("ğŸ’¡ å¸¸è§é—®é¢˜:")
        print("   1. æ•°æ®ç›®å½•ä¸å­˜åœ¨æˆ–ä¸ºç©º")
        print("   2. ç¼ºå°‘é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶")
        print("   3. æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        print("   4. ä¾èµ–åº“æœªå®‰è£…")
        print("ğŸ’¡ æ‰€æœ‰é…ç½®å‚æ•°éƒ½åœ¨ options/base_options.py ä¸­å®šä¹‰")


if __name__ == "__main__":
    main()
