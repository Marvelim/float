#!/usr/bin/env python3
"""
ä¸€é”®è¿è¡Œæ•°æ®é›†æµ‹è¯•è„šæœ¬
æŒ‰æ¨èé¡ºåºè¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼Œå¹¶æä¾›æ¸…æ™°çš„ç»“æœæŠ¥å‘Š
"""

import os
import sys
import subprocess
import argparse
from pathlib import Path


def run_command(cmd, description):
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
    print(f"\n{'='*60}")
    print(f"ğŸ”„ {description}")
    print(f"å‘½ä»¤: {' '.join(cmd)}")
    print('='*60)
    
    try:
        result = subprocess.run(cmd, capture_output=False, text=True, check=False)
        return result.returncode == 0
    except Exception as e:
        print(f"âŒ è¿è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}")
        return False


def check_scripts_exist():
    """æ£€æŸ¥æµ‹è¯•è„šæœ¬æ˜¯å¦å­˜åœ¨"""
    required_scripts = [
        'test_dataset_config.py',
        'quick_test_dataset.py', 
        'test_dataset.py'
    ]
    
    missing_scripts = []
    for script in required_scripts:
        if not os.path.exists(script):
            missing_scripts.append(script)
    
    if missing_scripts:
        print("âŒ ç¼ºå°‘æµ‹è¯•è„šæœ¬:")
        for script in missing_scripts:
            print(f"   {script}")
        return False
    
    return True


def main():
    parser = argparse.ArgumentParser(description='ä¸€é”®è¿è¡Œæ•°æ®é›†æµ‹è¯•')
    parser.add_argument('--data_root', type=str,
                       help='æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--config', type=str, default='training/example_config.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--skip_full_test', action='store_true',
                       help='è·³è¿‡å®Œæ•´æµ‹è¯•ï¼Œåªè¿è¡Œé…ç½®æ£€æŸ¥å’Œå¿«é€Ÿæµ‹è¯•')
    parser.add_argument('--create_sample_config', action='store_true',
                       help='åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶åé€€å‡º')
    
    args = parser.parse_args()
    
    print("ğŸš€ FLOAT æ•°æ®é›†æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    # åˆ›å»ºç¤ºä¾‹é…ç½®
    if args.create_sample_config:
        cmd = ['python', 'test_dataset_config.py', '--create_sample']
        run_command(cmd, "åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶")
        return
    
    # æ£€æŸ¥æµ‹è¯•è„šæœ¬æ˜¯å¦å­˜åœ¨
    if not check_scripts_exist():
        print("\nğŸ’¡ è¯·ç¡®ä¿æ‰€æœ‰æµ‹è¯•è„šæœ¬éƒ½åœ¨å½“å‰ç›®å½•ä¸­")
        return
    
    # æ„å»ºé€šç”¨å‚æ•°
    common_args = []
    if args.data_root:
        common_args.extend(['--data_root', args.data_root])
    if args.config and os.path.exists(args.config):
        common_args.extend(['--config', args.config])
    
    # æµ‹è¯•ç»“æœè·Ÿè¸ª
    test_results = {}
    
    # æ­¥éª¤ 1: é…ç½®æ£€æŸ¥
    print("\nğŸ¯ æ­¥éª¤ 1/3: é…ç½®æ£€æŸ¥")
    cmd = ['python', 'test_dataset_config.py'] + common_args
    test_results['config_check'] = run_command(cmd, "æ£€æŸ¥æ•°æ®é›†é…ç½®")
    
    if not test_results['config_check']:
        print("\nğŸ’¥ é…ç½®æ£€æŸ¥å¤±è´¥ï¼")
        print("ğŸ’¡ è¯·æ ¹æ®ä¸Šè¿°é”™è¯¯ä¿¡æ¯ä¿®å¤é…ç½®é—®é¢˜åé‡è¯•")
        print("ğŸ’¡ å¯ä»¥ä½¿ç”¨ --create_sample_config åˆ›å»ºç¤ºä¾‹é…ç½®")
        return
    
    # æ­¥éª¤ 2: å¿«é€Ÿæµ‹è¯•
    print("\nğŸ¯ æ­¥éª¤ 2/3: å¿«é€ŸåŠŸèƒ½æµ‹è¯•")
    cmd = ['python', 'quick_test_dataset.py'] + common_args
    test_results['quick_test'] = run_command(cmd, "å¿«é€Ÿæ•°æ®é›†åŠŸèƒ½æµ‹è¯•")
    
    if not test_results['quick_test']:
        print("\nğŸ’¥ å¿«é€Ÿæµ‹è¯•å¤±è´¥ï¼")
        print("ğŸ’¡ è¯·æ£€æŸ¥æ•°æ®ç›®å½•å’Œæ–‡ä»¶æ˜¯å¦æ­£ç¡®")
        print("ğŸ’¡ å¯ä»¥è¿è¡Œ: python quick_test_dataset.py --check_structure")
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­å®Œæ•´æµ‹è¯•
        if not args.skip_full_test:
            try:
                response = input("\nâ“ æ˜¯å¦ç»§ç»­è¿è¡Œå®Œæ•´æµ‹è¯•ï¼Ÿ(y/N): ").strip().lower()
                if response != 'y':
                    return
            except KeyboardInterrupt:
                print("\nğŸ‘‹ æµ‹è¯•å·²å–æ¶ˆ")
                return
    
    # æ­¥éª¤ 3: å®Œæ•´æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
    if not args.skip_full_test:
        print("\nğŸ¯ æ­¥éª¤ 3/3: å®Œæ•´æµ‹è¯•")
        cmd = ['python', 'test_dataset.py'] + common_args
        test_results['full_test'] = run_command(cmd, "å®Œæ•´æ•°æ®é›†æµ‹è¯•")
    else:
        print("\nâ­ï¸  è·³è¿‡å®Œæ•´æµ‹è¯•")
        test_results['full_test'] = None
    
    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)
    
    # ç»“æœç»Ÿè®¡
    passed = sum(1 for result in test_results.values() if result is True)
    failed = sum(1 for result in test_results.values() if result is False)
    skipped = sum(1 for result in test_results.values() if result is None)
    
    print(f"âœ… é€šè¿‡: {passed}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"â­ï¸  è·³è¿‡: {skipped}")
    
    # è¯¦ç»†ç»“æœ
    test_names = {
        'config_check': 'é…ç½®æ£€æŸ¥',
        'quick_test': 'å¿«é€Ÿæµ‹è¯•', 
        'full_test': 'å®Œæ•´æµ‹è¯•'
    }
    
    print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    for key, result in test_results.items():
        name = test_names.get(key, key)
        if result is True:
            print(f"   âœ… {name}: é€šè¿‡")
        elif result is False:
            print(f"   âŒ {name}: å¤±è´¥")
        else:
            print(f"   â­ï¸  {name}: è·³è¿‡")
    
    # æœ€ç»ˆå»ºè®®
    print(f"\nğŸ’¡ å»ºè®®:")
    if all(r is not False for r in test_results.values()):
        print("   ğŸ‰ æµ‹è¯•é€šè¿‡ï¼æ•°æ®é›†é…ç½®æ­£ç¡®ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ")
        print("   ğŸ“ ä¸‹ä¸€æ­¥: è¿è¡Œè®­ç»ƒè„šæœ¬")
    else:
        print("   ğŸ”§ è¯·æ ¹æ®ä¸Šè¿°é”™è¯¯ä¿¡æ¯ä¿®å¤é—®é¢˜")
        print("   ğŸ“– è¯¦ç»†è¯´æ˜è¯·æŸ¥çœ‹: README_dataset_testing.md")
    
    # å¸¸ç”¨å‘½ä»¤æç¤º
    print(f"\nğŸ› ï¸  å¸¸ç”¨å‘½ä»¤:")
    print("   æ£€æŸ¥æ•°æ®ç»“æ„: python quick_test_dataset.py --check_structure")
    print("   åˆ›å»ºç¤ºä¾‹é…ç½®: python test_dataset_config.py --create_sample")
    print("   æŸ¥çœ‹å¸®åŠ©æ–‡æ¡£: cat README_dataset_testing.md")


if __name__ == "__main__":
    main()
