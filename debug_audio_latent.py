#!/usr/bin/env python3
"""
éŸ³é¢‘æ½œåœ¨è¡¨ç¤ºè°ƒè¯•è„šæœ¬
ä¸“é—¨è°ƒè¯• audio_latent ç»´åº¦é—®é¢˜
"""

import os
import sys
import torch
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from training.dataset import FLOATDataset
from options.base_options import BaseOptions
from models.float.FLOAT import AudioEncoder


def debug_audio_processing():
    """è°ƒè¯•éŸ³é¢‘å¤„ç†æµç¨‹"""
    print("ğŸ” è°ƒè¯•éŸ³é¢‘å¤„ç†æµç¨‹...")
    
    try:
        # è·å–é…ç½®
        opt = BaseOptions().parse()
        print(f"é…ç½®ä¿¡æ¯:")
        print(f"  wav2vec_sec: {opt.wav2vec_sec}")
        print(f"  fps: {opt.fps}")
        print(f"  sampling_rate: {opt.sampling_rate}")
        print(f"  num_prev_frames: {opt.num_prev_frames}")
        print(f"  dim_a: {opt.dim_a}")
        
        # è®¡ç®—é¢„æœŸçš„åºåˆ—é•¿åº¦
        expected_seq_len = int(opt.wav2vec_sec * opt.fps)
        print(f"  é¢„æœŸåºåˆ—é•¿åº¦: {expected_seq_len}")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = FLOATDataset(
            data_root=opt.data_root,
            train=True,
            opt=opt
        )
        
        if len(dataset) == 0:
            print("âŒ æ•°æ®é›†ä¸ºç©º")
            return
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œå¤§å°: {len(dataset)}")
        
        # è·å–ç¬¬ä¸€ä¸ªæ•°æ®é¡¹çš„è·¯å¾„ä¿¡æ¯
        data_item = dataset.data_list[0]
        print(f"\nğŸ“ æµ‹è¯•æ•°æ®é¡¹:")
        print(f"  è§†é¢‘è·¯å¾„: {data_item['video_path']}")
        print(f"  éŸ³é¢‘è·¯å¾„: {data_item['audio_path']}")
        
        # æ‰‹åŠ¨æµ‹è¯•éŸ³é¢‘åŠ è½½
        print(f"\nğŸµ æ‰‹åŠ¨æµ‹è¯•éŸ³é¢‘åŠ è½½...")
        audio_tensor = dataset._load_audio(data_item['audio_path'])
        print(f"  åŸå§‹éŸ³é¢‘å¼ é‡å½¢çŠ¶: {audio_tensor.shape}")
        
        # æ‰‹åŠ¨æµ‹è¯•è§†é¢‘åŠ è½½
        print(f"\nğŸ¬ æ‰‹åŠ¨æµ‹è¯•è§†é¢‘åŠ è½½...")
        video_frames = dataset._load_video(data_item['video_path'])
        print(f"  è§†é¢‘å¸§å½¢çŠ¶: {video_frames.shape}")
        num_frames = video_frames.shape[0]
        print(f"  è§†é¢‘å¸§æ•°: {num_frames}")
        
        # æ‰‹åŠ¨æµ‹è¯•éŸ³é¢‘ç¼–ç å™¨
        print(f"\nğŸ”Š æ‰‹åŠ¨æµ‹è¯•éŸ³é¢‘ç¼–ç å™¨...")
        audio_encoder = AudioEncoder(opt)
        
        print(f"  éŸ³é¢‘ç¼–ç å™¨é…ç½®:")
        print(f"    num_frames_for_clip: {audio_encoder.num_frames_for_clip}")
        print(f"    num_prev_frames: {audio_encoder.num_prev_frames}")
        print(f"    only_last_features: {audio_encoder.only_last_features}")
        
        # æµ‹è¯•éŸ³é¢‘ç¼–ç å™¨æ¨ç†
        print(f"\nğŸ§  æµ‹è¯•éŸ³é¢‘ç¼–ç å™¨æ¨ç†...")
        print(f"  è¾“å…¥éŸ³é¢‘å½¢çŠ¶: {audio_tensor.shape}")
        print(f"  ç›®æ ‡åºåˆ—é•¿åº¦: {num_frames}")
        
        w_audio = audio_encoder.inference(audio_tensor, seq_len=num_frames)
        print(f"  è¾“å‡ºéŸ³é¢‘ç‰¹å¾å½¢çŠ¶: {w_audio.shape}")
        
        # åˆ†æé—®é¢˜
        print(f"\nğŸ” é—®é¢˜åˆ†æ:")
        if w_audio.shape[0] == 0:
            print("  âŒ ç¬¬ä¸€ç»´ä¸º0ï¼Œè¯´æ˜æ²¡æœ‰ç”Ÿæˆä»»ä½•ç‰¹å¾")
            print("  å¯èƒ½åŸå› :")
            print("    1. éŸ³é¢‘æ–‡ä»¶ä¸ºç©ºæˆ–æŸå")
            print("    2. wav2vec2 æ¨¡å‹å¤„ç†å¤±è´¥")
            print("    3. linear_interpolation å‡½æ•°é—®é¢˜")
        
        expected_shape = (1, num_frames, opt.dim_a)
        print(f"  æœŸæœ›å½¢çŠ¶: {expected_shape}")
        print(f"  å®é™…å½¢çŠ¶: {w_audio.shape}")
        
        # æµ‹è¯•åºåˆ—åˆ‡ç‰‡
        print(f"\nâœ‚ï¸  æµ‹è¯•åºåˆ—åˆ‡ç‰‡...")
        start_idx = 0
        end_idx = min(num_frames, expected_seq_len)
        prev_frames = min(dataset.prev_frames, num_frames)
        
        print(f"  start_idx: {start_idx}")
        print(f"  end_idx: {end_idx}")
        print(f"  prev_frames: {prev_frames}")
        
        if w_audio.shape[1] > 0:  # å¦‚æœæœ‰æ•°æ®
            w_audio_cur = w_audio[:, start_idx + prev_frames:end_idx]
            w_audio_prev = w_audio[:, start_idx:start_idx + prev_frames]
            
            print(f"  w_audio_cur å½¢çŠ¶: {w_audio_cur.shape}")
            print(f"  w_audio_prev å½¢çŠ¶: {w_audio_prev.shape}")
        else:
            print("  âŒ æ— æ³•è¿›è¡Œåˆ‡ç‰‡ï¼Œå› ä¸ºéŸ³é¢‘ç‰¹å¾ä¸ºç©º")
        
        return True
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        print("ğŸ” é”™è¯¯è¯¦æƒ…:")
        print(traceback.format_exc())
        return False


def debug_wav2vec_model():
    """è°ƒè¯• wav2vec æ¨¡å‹"""
    print("\nğŸ” è°ƒè¯• wav2vec æ¨¡å‹...")
    
    try:
        opt = BaseOptions().parse()
        
        # æ£€æŸ¥æ¨¡å‹è·¯å¾„
        if not os.path.exists(opt.wav2vec_model_path):
            print(f"âŒ wav2vec æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {opt.wav2vec_model_path}")
            return False
        
        print(f"âœ… wav2vec æ¨¡å‹è·¯å¾„å­˜åœ¨: {opt.wav2vec_model_path}")
        
        # å°è¯•åŠ è½½æ¨¡å‹
        from transformers import Wav2Vec2FeatureExtractor
        from models.wav2vec2 import Wav2VecModel
        
        print("ğŸ”„ åŠ è½½ wav2vec é¢„å¤„ç†å™¨...")
        preprocessor = Wav2Vec2FeatureExtractor.from_pretrained(
            opt.wav2vec_model_path, 
            local_files_only=True
        )
        print("âœ… wav2vec é¢„å¤„ç†å™¨åŠ è½½æˆåŠŸ")
        
        print("ğŸ”„ åŠ è½½ wav2vec æ¨¡å‹...")
        model = Wav2VecModel.from_pretrained(
            opt.wav2vec_model_path, 
            local_files_only=True
        )
        print("âœ… wav2vec æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•æ¨¡å‹é…ç½®
        print(f"ğŸ“‹ æ¨¡å‹é…ç½®:")
        print(f"  hidden_size: {model.config.hidden_size}")
        print(f"  num_hidden_layers: {model.config.num_hidden_layers}")
        
        return True
        
    except Exception as e:
        print(f"âŒ wav2vec æ¨¡å‹è°ƒè¯•å¤±è´¥: {e}")
        print(traceback.format_exc())
        return False


def test_linear_interpolation():
    """æµ‹è¯•çº¿æ€§æ’å€¼å‡½æ•°"""
    print("\nğŸ” æµ‹è¯•çº¿æ€§æ’å€¼å‡½æ•°...")
    
    try:
        from models.wav2vec2 import linear_interpolation
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 1
        feature_dim = 768
        original_seq_len = 100
        target_seq_len = 50
        
        # åˆ›å»ºéšæœºç‰¹å¾
        features = torch.randn(batch_size, original_seq_len, feature_dim)
        print(f"è¾“å…¥ç‰¹å¾å½¢çŠ¶: {features.shape}")
        
        # åº”ç”¨çº¿æ€§æ’å€¼
        interpolated = linear_interpolation(features, target_seq_len)
        print(f"æ’å€¼åç‰¹å¾å½¢çŠ¶: {interpolated.shape}")
        
        if interpolated.shape[1] == target_seq_len:
            print("âœ… çº¿æ€§æ’å€¼å‡½æ•°å·¥ä½œæ­£å¸¸")
            return True
        else:
            print("âŒ çº¿æ€§æ’å€¼å‡½æ•°è¾“å‡ºå½¢çŠ¶ä¸æ­£ç¡®")
            return False
        
    except Exception as e:
        print(f"âŒ çº¿æ€§æ’å€¼æµ‹è¯•å¤±è´¥: {e}")
        print(traceback.format_exc())
        return False


def main():
    print("ğŸš€ éŸ³é¢‘æ½œåœ¨è¡¨ç¤ºè°ƒè¯•")
    print("=" * 60)
    
    # æµ‹è¯•æ­¥éª¤
    tests = [
        ("wav2vec æ¨¡å‹", debug_wav2vec_model),
        ("çº¿æ€§æ’å€¼å‡½æ•°", test_linear_interpolation),
        ("éŸ³é¢‘å¤„ç†æµç¨‹", debug_audio_processing),
    ]
    
    results = {}
    for name, test_func in tests:
        print(f"\n{'='*20} {name} {'='*20}")
        results[name] = test_func()
    
    # æ€»ç»“
    print(f"\n{'='*60}")
    print("ğŸ“Š è°ƒè¯•ç»“æœæ€»ç»“:")
    for name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {name}: {status}")
    
    # é—®é¢˜è¯Šæ–­
    print(f"\nğŸ” é—®é¢˜è¯Šæ–­:")
    if not results.get("wav2vec æ¨¡å‹", False):
        print("  1. wav2vec æ¨¡å‹åŠ è½½å¤±è´¥ - æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")
    elif not results.get("çº¿æ€§æ’å€¼å‡½æ•°", False):
        print("  2. çº¿æ€§æ’å€¼å‡½æ•°æœ‰é—®é¢˜ - æ£€æŸ¥å®ç°")
    elif not results.get("éŸ³é¢‘å¤„ç†æµç¨‹", False):
        print("  3. éŸ³é¢‘å¤„ç†æµç¨‹æœ‰é—®é¢˜ - éœ€è¦è¯¦ç»†è°ƒè¯•")
    else:
        print("  æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œé—®é¢˜å¯èƒ½åœ¨æ•°æ®é›†çš„å…¶ä»–éƒ¨åˆ†")
    
    print(f"\nğŸ’¡ å»ºè®®:")
    print("  1. æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º")
    print("  2. æ£€æŸ¥ wav2vec æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§")
    print("  3. æ£€æŸ¥é…ç½®å‚æ•°æ˜¯å¦åˆç†")
    print("  4. æ£€æŸ¥æ•°æ®é›†çš„åºåˆ—åˆ‡ç‰‡é€»è¾‘")


if __name__ == "__main__":
    main()
