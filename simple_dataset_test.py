#!/usr/bin/env python3
"""
ç®€å•æ•°æ®é›†æµ‹è¯•è„šæœ¬
ä¸“é—¨é’ˆå¯¹ BaseOptions é…ç½®ç³»ç»Ÿï¼Œä¸ä¾èµ– JSON é…ç½®æ–‡ä»¶
"""

import os
import sys
import torch
import traceback
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from training.dataset import FLOATDataset
from options.base_options import BaseOptions


def test_base_options():
    """æµ‹è¯• BaseOptions é…ç½®è§£æ"""
    print("ğŸ” æµ‹è¯• BaseOptions é…ç½®è§£æ...")
    
    try:
        opt = BaseOptions().parse()
        print("âœ… BaseOptions è§£ææˆåŠŸ")
        
        # æ˜¾ç¤ºå…³é”®é…ç½®
        key_configs = [
            'data_root', 'input_size', 'dim_w', 'dim_m', 'dim_a', 'dim_e',
            'fps', 'sampling_rate', 'wav2vec_sec', 'num_prev_frames',
            'wav2vec_model_path', 'audio2emotion_path'
        ]
        
        print("ğŸ“‹ å…³é”®é…ç½®å‚æ•°:")
        for key in key_configs:
            if hasattr(opt, key):
                value = getattr(opt, key)
                print(f"   {key}: {value}")
            else:
                print(f"   {key}: âŒ æœªå®šä¹‰")
        
        return opt
        
    except Exception as e:
        print(f"âŒ BaseOptions è§£æå¤±è´¥: {e}")
        print(traceback.format_exc())
        return None


def check_paths(opt):
    """æ£€æŸ¥è·¯å¾„é…ç½®"""
    print("\nğŸ” æ£€æŸ¥è·¯å¾„é…ç½®...")
    
    issues = []
    
    # æ£€æŸ¥æ•°æ®æ ¹ç›®å½•
    if hasattr(opt, 'data_root'):
        if os.path.exists(opt.data_root):
            print(f"âœ… æ•°æ®æ ¹ç›®å½•å­˜åœ¨: {opt.data_root}")
        else:
            issues.append(f"æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {opt.data_root}")
    else:
        issues.append("é…ç½®ä¸­ç¼ºå°‘ data_root")
    
    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    model_paths = [
        ('wav2vec_model_path', 'Wav2Vec2æ¨¡å‹'),
        ('audio2emotion_path', 'éŸ³é¢‘æƒ…æ„Ÿæ¨¡å‹')
    ]
    
    for attr, desc in model_paths:
        if hasattr(opt, attr):
            path = getattr(opt, attr)
            if os.path.exists(path):
                print(f"âœ… {desc}è·¯å¾„å­˜åœ¨: {path}")
            else:
                issues.append(f"{desc}è·¯å¾„ä¸å­˜åœ¨: {path}")
        else:
            issues.append(f"é…ç½®ä¸­ç¼ºå°‘ {attr}")
    
    if issues:
        print("âŒ å‘ç°é—®é¢˜:")
        for issue in issues:
            print(f"   - {issue}")
        return False
    else:
        print("âœ… æ‰€æœ‰è·¯å¾„æ£€æŸ¥é€šè¿‡")
        return True


def test_dataset_creation(opt):
    """æµ‹è¯•æ•°æ®é›†åˆ›å»º"""
    print("\nğŸ” æµ‹è¯•æ•°æ®é›†åˆ›å»º...")
    
    try:
        dataset = FLOATDataset(
            data_root=opt.data_root,
            train=True,
            opt=opt
        )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        if len(dataset) == 0:
            print("âš ï¸  è­¦å‘Š: æ•°æ®é›†ä¸ºç©º")
            return False, None
        
        return True, dataset
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        print("ğŸ” é”™è¯¯è¯¦æƒ…:")
        print(traceback.format_exc())
        return False, None


def test_data_loading(dataset):
    """æµ‹è¯•å•ä¸ªæ•°æ®åŠ è½½"""
    print("\nğŸ” æµ‹è¯•å•ä¸ªæ•°æ®åŠ è½½...")

    try:
        # åŠ è½½ç¬¬ä¸€ä¸ªæ•°æ®é¡¹
        data_item = dataset[0]

        print("âœ… æ•°æ®é¡¹åŠ è½½æˆåŠŸ")
        print("ğŸ“‹ æ•°æ®é¡¹ç»“æ„:")

        for key, value in data_item.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {tuple(value.shape)} ({value.dtype})")
            else:
                print(f"   {key}: {type(value)} = {value}")

        # æ£€æŸ¥å¿…è¦çš„é”®
        required_keys = ['video_cur', 'audio_latent_cur', 'emotion_features']
        missing_keys = [key for key in required_keys if key not in data_item]

        if missing_keys:
            print(f"âš ï¸  ç¼ºå°‘å¿…è¦çš„é”®: {missing_keys}")
            return False
        else:
            print("âœ… åŒ…å«æ‰€æœ‰å¿…è¦çš„æ•°æ®é”®")

        # æ£€æŸ¥éŸ³é¢‘æ½œåœ¨è¡¨ç¤ºçš„é—®é¢˜
        audio_cur = data_item.get('audio_latent_cur')
        audio_prev = data_item.get('audio_latent_prev')

        if audio_cur is not None and audio_cur.shape[0] == 0:
            print("âš ï¸  è­¦å‘Š: audio_latent_cur ç¬¬ä¸€ç»´ä¸º0ï¼Œè¿™æ˜¯é—®é¢˜æ‰€åœ¨ï¼")
            print(f"   å®é™…å½¢çŠ¶: {audio_cur.shape}")
            print(f"   æœŸæœ›å½¢çŠ¶: (å¸§æ•°, 512)")

        if audio_prev is not None and audio_prev.shape[0] == 0:
            print("âš ï¸  è­¦å‘Š: audio_latent_prev ç¬¬ä¸€ç»´ä¸º0ï¼Œè¿™æ˜¯é—®é¢˜æ‰€åœ¨ï¼")
            print(f"   å®é™…å½¢çŠ¶: {audio_prev.shape}")
            print(f"   æœŸæœ›å½¢çŠ¶: (å¸§æ•°, 512)")

        return True

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        print(traceback.format_exc())
        return False


def test_batch_loading(dataset):
    """æµ‹è¯•æ‰¹é‡æ•°æ®åŠ è½½"""
    print("\nğŸ” æµ‹è¯•æ‰¹é‡æ•°æ®åŠ è½½...")

    try:
        from torch.utils.data import DataLoader

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼Œä½¿ç”¨å°æ‰¹é‡
        batch_size = 2
        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
            pin_memory=False,
            drop_last=False
        )

        print(f"ğŸ“¦ åˆ›å»ºæ•°æ®åŠ è½½å™¨æˆåŠŸï¼Œæ‰¹é‡å¤§å°: {batch_size}")

        # è·å–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
        batch_iter = iter(dataloader)
        batch = next(batch_iter)

        print("âœ… æ‰¹é‡æ•°æ®åŠ è½½æˆåŠŸ")
        print("ğŸ“‹ æ‰¹é‡æ•°æ®ç»“æ„:")

        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {tuple(value.shape)} ({value.dtype})")
            elif isinstance(value, (list, tuple)):
                print(f"   {key}: {type(value)} (é•¿åº¦: {len(value)})")
                if len(value) > 0:
                    print(f"      ç¤ºä¾‹: {value[0]}")
            else:
                print(f"   {key}: {type(value)} = {value}")

        # è¯¦ç»†åˆ†æéŸ³é¢‘æ½œåœ¨è¡¨ç¤º
        if 'audio_latent_cur' in batch:
            audio_cur_batch = batch['audio_latent_cur']
            print(f"\nğŸ” éŸ³é¢‘æ½œåœ¨è¡¨ç¤ºè¯¦ç»†åˆ†æ:")
            print(f"   audio_latent_cur æ‰¹é‡å½¢çŠ¶: {audio_cur_batch.shape}")

            if audio_cur_batch.shape[1] == 0:
                print("   âŒ é—®é¢˜ç¡®è®¤: æ‰¹é‡ä¸­æ‰€æœ‰æ ·æœ¬çš„ audio_latent_cur ç¬¬äºŒç»´éƒ½ä¸º0")
                print("   è¿™è¯´æ˜é—®é¢˜å‡ºç°åœ¨å•ä¸ªæ ·æœ¬çš„å¤„ç†é˜¶æ®µ")
            else:
                print("   âœ… æ‰¹é‡å¤„ç†æ­£å¸¸")

        if 'audio_latent_prev' in batch:
            audio_prev_batch = batch['audio_latent_prev']
            print(f"   audio_latent_prev æ‰¹é‡å½¢çŠ¶: {audio_prev_batch.shape}")

            if audio_prev_batch.shape[1] == 0:
                print("   âŒ é—®é¢˜ç¡®è®¤: æ‰¹é‡ä¸­æ‰€æœ‰æ ·æœ¬çš„ audio_latent_prev ç¬¬äºŒç»´éƒ½ä¸º0")
            else:
                print("   âœ… æ‰¹é‡å¤„ç†æ­£å¸¸")

        return True

    except Exception as e:
        print(f"âŒ æ‰¹é‡æ•°æ®åŠ è½½å¤±è´¥: {e}")
        print("ğŸ” é”™è¯¯è¯¦æƒ…:")
        print(traceback.format_exc())
        return False


def main():
    print("ğŸš€ ç®€å•æ•°æ®é›†æµ‹è¯• (åŸºäº BaseOptions)")
    print("=" * 60)
    
    # æ­¥éª¤ 1: æµ‹è¯•é…ç½®è§£æ
    opt = test_base_options()
    if opt is None:
        print("\nğŸ’¥ é…ç½®è§£æå¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        return
    
    # æ­¥éª¤ 2: æ£€æŸ¥è·¯å¾„
    paths_ok = check_paths(opt)
    if not paths_ok:
        print("\nğŸ’¥ è·¯å¾„æ£€æŸ¥å¤±è´¥")
        print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("   1. ä½¿ç”¨ --data_root å‚æ•°æŒ‡å®šæ­£ç¡®çš„æ•°æ®ç›®å½•")
        print("   2. ç¡®ä¿é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶å­˜åœ¨äºæŒ‡å®šè·¯å¾„")
        print("   3. æ£€æŸ¥ options/base_options.py ä¸­çš„é»˜è®¤è·¯å¾„è®¾ç½®")
        return
    
    # æ­¥éª¤ 3: æµ‹è¯•æ•°æ®é›†åˆ›å»º
    dataset_ok, dataset = test_dataset_creation(opt)
    if not dataset_ok:
        print("\nğŸ’¥ æ•°æ®é›†åˆ›å»ºå¤±è´¥")
        print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("   1. æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„æ˜¯å¦æ­£ç¡®")
        print("   2. ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®")
        print("   3. æ£€æŸ¥ä¾èµ–åº“æ˜¯å¦æ­£ç¡®å®‰è£…")
        return
    
    # æ­¥éª¤ 4: æµ‹è¯•å•ä¸ªæ•°æ®åŠ è½½
    loading_ok = test_data_loading(dataset)
    if not loading_ok:
        print("\nğŸ’¥ å•ä¸ªæ•°æ®åŠ è½½å¤±è´¥")
        return

    # æ­¥éª¤ 5: æµ‹è¯•æ‰¹é‡æ•°æ®åŠ è½½
    batch_ok = test_batch_loading(dataset)
    if not batch_ok:
        print("\nğŸ’¥ æ‰¹é‡æ•°æ®åŠ è½½å¤±è´¥")
        return

    # æˆåŠŸæ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("ğŸ“Š æµ‹è¯•ç»“æœ:")
    print("   âœ… BaseOptions é…ç½®è§£ææ­£å¸¸")
    print("   âœ… è·¯å¾„é…ç½®æ­£ç¡®")
    print("   âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
    print("   âœ… å•ä¸ªæ•°æ®åŠ è½½æ­£å¸¸")
    print("   âœ… æ‰¹é‡æ•°æ®åŠ è½½æ­£å¸¸")
    
    print(f"\nğŸ“‹ æ•°æ®é›†ä¿¡æ¯:")
    print(f"   æ•°æ®é›†å¤§å°: {len(dataset)}")
    print(f"   æ•°æ®æ ¹ç›®å½•: {opt.data_root}")
    print(f"   è¾“å…¥å°ºå¯¸: {opt.input_size}")
    print(f"   æ‰¹æ¬¡å¤§å°: {getattr(opt, 'batch_size', 'æœªè®¾ç½®')}")
    
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("   å¯ä»¥å¼€å§‹è®­ç»ƒ: python training/train.py")
    print("   æˆ–è¿è¡Œå®Œæ•´æµ‹è¯•: python test_dataset.py")


if __name__ == "__main__":
    # æ”¯æŒåŸºæœ¬çš„å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        print("ğŸ’¡ æç¤º: æ­¤è„šæœ¬ä½¿ç”¨ BaseOptions è§£ææ‰€æœ‰å‚æ•°")
        print("ğŸ’¡ å¯ç”¨å‚æ•°è¯·æŸ¥çœ‹: options/base_options.py")
        print("ğŸ’¡ ç¤ºä¾‹: python simple_dataset_test.py --data_root /path/to/data")
        print()
    
    main()
