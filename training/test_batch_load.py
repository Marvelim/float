#!/usr/bin/env python3
"""
æµ‹è¯•æ‰¹å¤„ç† load å‡½æ•°
"""

import os
import sys
import torch
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from options.base_options import BaseOptions
from training.dataset import create_dataloader
from models.float.FLOAT import FLOAT
from training.train import load

os.environ['CUDA_VISIBLE_DEVICES'] = '4,5,6,7'

def test_batch_load():
    """æµ‹è¯•æ‰¹å¤„ç† load å‡½æ•°"""
    print("æµ‹è¯•æ‰¹å¤„ç† load å‡½æ•°...")
    
    # è§£æé€‰é¡¹
    opt = BaseOptions().parse()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    opt.rank = device
    
    # åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºæ¨¡å‹...")
    model = FLOAT(opt).to(device)
    model.audio_encoder.requires_grad_(False)
    model.emotion_encoder.requires_grad_(False)
    model.motion_autoencoder.requires_grad_(False)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    dataloader = create_dataloader(
        data_root="../datasets/ravdess_processed",
        batch_size=2,  # æ›´å°çš„æ‰¹æ¬¡æµ‹è¯•
        num_workers=0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
        train=True,
        opt=opt
    )
    
    # è·å–ä¸€ä¸ªæ‰¹æ¬¡
    print("è·å–æ‰¹æ¬¡æ•°æ®...")
    batch_data = next(iter(dataloader))
    print(f"åŸå§‹æ‰¹æ¬¡å¤§å°: {len(batch_data)}")
    
    # æµ‹è¯•æ‰¹å¤„ç† load å‡½æ•°
    print("æµ‹è¯•æ‰¹å¤„ç† load å‡½æ•°...")
    start_time = time.time()
    
    try:
        processed_data = load(batch_data, model, device, opt)
        end_time = time.time()
        
        print(f"âœ… æ‰¹å¤„ç† load å‡½æ•°æ‰§è¡ŒæˆåŠŸï¼")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {end_time - start_time:.2f} ç§’")
        print(f"ğŸ“Š å¤„ç†åçš„æ•°æ®é”®: {list(processed_data.keys())}")
        
        for key, value in processed_data.items():
            if isinstance(value, torch.Tensor):
                print(f"  {key}: {value.shape} ({value.dtype})")
            else:
                print(f"  {key}: {type(value)} - {len(value) if hasattr(value, '__len__') else 'N/A'}")
        
        # éªŒè¯å®Œæ•´æ•°æ®å½¢çŠ¶
        actual_batch_size = processed_data['full_videos'].shape[0]  # ä½¿ç”¨å®é™…æ‰¹æ¬¡å¤§å°
        target_frames = processed_data['target_frames']
        
        expected_shapes = {
            'full_videos': (actual_batch_size, target_frames, 3, opt.input_size, opt.input_size),
            'full_motion_latent': (actual_batch_size, target_frames, opt.dim_w),  # ä½¿ç”¨ dim_w è€Œä¸æ˜¯ dim_m
            'full_audio_latent': (actual_batch_size, target_frames, opt.dim_a),
            'emotion_features': (actual_batch_size, opt.dim_e),
        }
        
        print("\nğŸ” éªŒè¯å®Œæ•´æ•°æ®å½¢çŠ¶:")
        all_correct = True
        for key, expected_shape in expected_shapes.items():
            if key in processed_data:
                actual_shape = processed_data[key].shape
                if actual_shape == expected_shape:
                    print(f"  âœ… {key}: {actual_shape}")
                else:
                    print(f"  âŒ {key}: æœŸæœ› {expected_shape}, å®é™… {actual_shape}")
                    all_correct = False
            else:
                print(f"  âŒ {key}: ç¼ºå¤±")
                all_correct = False
        
        # æµ‹è¯• get_batch_sample å‡½æ•°
        print("\nğŸ§ª æµ‹è¯• get_batch_sample å‡½æ•°...")
        from training.train import get_batch_sample
        
        try:
            batch_sample = get_batch_sample(processed_data, opt)
            print("âœ… get_batch_sample æ‰§è¡ŒæˆåŠŸï¼")
            
            # éªŒè¯åˆ‡åˆ†åçš„æ•°æ®å½¢çŠ¶
            sequence_length = int(opt.wav2vec_sec * opt.fps)
            prev_frames = int(opt.num_prev_frames)
            actual_batch_size = batch_sample['video_cur'].shape[0]  # ä½¿ç”¨å®é™…æ‰¹æ¬¡å¤§å°
            
            expected_sample_shapes = {
                'video_cur': (actual_batch_size, sequence_length, 3, opt.input_size, opt.input_size),
                'video_prev': (actual_batch_size, prev_frames, 3, opt.input_size, opt.input_size),
                'motion_latent_cur': (actual_batch_size, sequence_length, opt.dim_w),  # ä½¿ç”¨ dim_w
                'motion_latent_prev': (actual_batch_size, prev_frames, opt.dim_w),    # ä½¿ç”¨ dim_w
                'audio_latent_cur': (actual_batch_size, sequence_length, opt.dim_a),
                'audio_latent_prev': (actual_batch_size, prev_frames, opt.dim_a),
                'reference_motion': (actual_batch_size, opt.dim_w),  # ä½¿ç”¨ dim_w
                'emotion_features': (actual_batch_size, opt.dim_e),
            }
            
            print("\nğŸ” éªŒè¯åˆ‡åˆ†åæ•°æ®å½¢çŠ¶:")
            sample_correct = True
            for key, expected_shape in expected_sample_shapes.items():
                if key in batch_sample:
                    actual_shape = batch_sample[key].shape
                    if actual_shape == expected_shape:
                        print(f"  âœ… {key}: {actual_shape}")
                    else:
                        print(f"  âŒ {key}: æœŸæœ› {expected_shape}, å®é™… {actual_shape}")
                        sample_correct = False
                else:
                    print(f"  âŒ {key}: ç¼ºå¤±")
                    sample_correct = False
            
            if sample_correct:
                print("\nğŸ‰ æ‰€æœ‰åˆ‡åˆ†åæ•°æ®å½¢çŠ¶éƒ½æ­£ç¡®ï¼")
                from models.float.FLOAT import FLOAT
                from models.float.FMT import FlowMatchingTransformer
                model = FLOAT(opt).to(device)
                model.audio_encoder.requires_grad_(False)
                model.emotion_encoder.requires_grad_(False)
                model.motion_autoencoder.requires_grad_(False)
                

            else:
                print("\nâš ï¸  éƒ¨åˆ†åˆ‡åˆ†åæ•°æ®å½¢çŠ¶ä¸æ­£ç¡®")
                
        except Exception as e:
            print(f"âŒ get_batch_sample æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        if all_correct:
            print("\nğŸ‰ æ‰€æœ‰å®Œæ•´æ•°æ®å½¢çŠ¶éƒ½æ­£ç¡®ï¼")
        else:
            print("\nâš ï¸  éƒ¨åˆ†å®Œæ•´æ•°æ®å½¢çŠ¶ä¸æ­£ç¡®")
            
    except Exception as e:
        print(f"âŒ æ‰¹å¤„ç† load å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_batch_load()
